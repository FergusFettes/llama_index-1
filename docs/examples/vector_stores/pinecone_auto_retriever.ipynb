{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "307804a3-c02b-4a57-ac0d-172c30ddc851",
            "metadata": {},
            "source": [
                "# Pinecone Vector Store - Auto Retriever"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "f7010b1d-d1bb-4f08-9309-a328bb4ea396",
            "metadata": {},
            "source": [
                "#### Creating a Pinecone Index"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "d48af8e1",
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "import sys\n",
                "import os\n",
                "\n",
                "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
                "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d6b97ca2",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:numexpr.utils:Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
                        "Note: NumExpr detected 12 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
                        "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
                        "NumExpr defaulting to 8 threads.\n"
                    ]
                }
            ],
            "source": [
                "import openai\n",
                "openai.api_base = \"https://oai.hconeai.com/v1\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "4ad14111-0bbb-4c62-906d-6d6253e0cdee",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/suo/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from tqdm.autonotebook import tqdm\n"
                    ]
                }
            ],
            "source": [
                "import pinecone\n",
                "\n",
                "api_key = os.environ['PINECONE_API_KEY']\n",
                "pinecone.init(api_key=api_key, environment=\"eu-west1-gcp\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "c2c90087-bdd9-4ca4-b06b-2af883559f88",
            "metadata": {},
            "outputs": [
                {
                    "ename": "ApiException",
                    "evalue": "(400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=UTF-8', 'date': 'Thu, 11 May 2023 03:54:14 GMT', 'x-envoy-upstream-service-time': '492', 'content-length': '131', 'server': 'envoy'})\nHTTP response body: The index exceeds the project quota of 1 pods by 1 pods. Upgrade your account or change the project settings to increase the quota.\n",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# dimensions are for text-embedding-ada-002\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m pinecone\u001b[39m.\u001b[39;49mcreate_index(\u001b[39m\"\u001b[39;49m\u001b[39mquickstart-index\u001b[39;49m\u001b[39m\"\u001b[39;49m, dimension\u001b[39m=\u001b[39;49m\u001b[39m1536\u001b[39;49m, metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m, pod_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mp1\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/manage.py:118\u001b[0m, in \u001b[0;36mcreate_index\u001b[0;34m(name, dimension, timeout, index_type, metric, replicas, shards, pods, pod_type, index_config, metadata_config, source_collection)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a Pinecone index.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39m:param name: the name of the index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m:param timeout: Timeout for wait until index gets ready. If None, wait indefinitely; if >=0, time out after this many seconds; if -1, return immediately and do not wait. Default: None\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m api_instance \u001b[39m=\u001b[39m _get_api_instance()\n\u001b[0;32m--> 118\u001b[0m api_instance\u001b[39m.\u001b[39;49mcreate_index(create_request\u001b[39m=\u001b[39;49mCreateRequest(\n\u001b[1;32m    119\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    120\u001b[0m     dimension\u001b[39m=\u001b[39;49mdimension,\n\u001b[1;32m    121\u001b[0m     index_type\u001b[39m=\u001b[39;49mindex_type,\n\u001b[1;32m    122\u001b[0m     metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    123\u001b[0m     replicas\u001b[39m=\u001b[39;49mreplicas,\n\u001b[1;32m    124\u001b[0m     shards\u001b[39m=\u001b[39;49mshards,\n\u001b[1;32m    125\u001b[0m     pods\u001b[39m=\u001b[39;49mpods,\n\u001b[1;32m    126\u001b[0m     pod_type\u001b[39m=\u001b[39;49mpod_type,\n\u001b[1;32m    127\u001b[0m     index_config\u001b[39m=\u001b[39;49mindex_config \u001b[39mor\u001b[39;49;00m {},\n\u001b[1;32m    128\u001b[0m     metadata_config\u001b[39m=\u001b[39;49mmetadata_config,\n\u001b[1;32m    129\u001b[0m     source_collection\u001b[39m=\u001b[39;49msource_collection\n\u001b[1;32m    130\u001b[0m ))\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_ready\u001b[39m():\n\u001b[1;32m    133\u001b[0m     status \u001b[39m=\u001b[39m _get_status(name)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:776\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    766\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    767\u001b[0m \u001b[39m    Example:\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    774\u001b[0m \n\u001b[1;32m    775\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcallable(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api/index_operations_api.py:370\u001b[0m, in \u001b[0;36mIndexOperationsApi.__init__.<locals>.__create_index\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    367\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m_check_return_type\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    368\u001b[0m )\n\u001b[1;32m    369\u001b[0m kwargs[\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39m_host_index\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 370\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_with_http_info(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:838\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    834\u001b[0m     header_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_client\u001b[39m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    835\u001b[0m         content_type_headers_list)\n\u001b[1;32m    836\u001b[0m     params[\u001b[39m'\u001b[39m\u001b[39mheader\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m header_list\n\u001b[0;32m--> 838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mendpoint_path\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mhttp_method\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    840\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    841\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    842\u001b[0m     params[\u001b[39m'\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    843\u001b[0m     body\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mbody\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    844\u001b[0m     post_params\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mform\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    845\u001b[0m     files\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mfile\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    846\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mresponse_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    847\u001b[0m     auth_settings\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msettings[\u001b[39m'\u001b[39;49m\u001b[39mauth\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    848\u001b[0m     async_req\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    849\u001b[0m     _check_type\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_check_return_type\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    850\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    851\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    852\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mkwargs[\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    853\u001b[0m     _host\u001b[39m=\u001b[39;49m_host,\n\u001b[1;32m    854\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mcollection_format\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:413\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 413\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    414\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    415\u001b[0m                            body, post_params, files,\n\u001b[1;32m    416\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    417\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    418\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    419\u001b[0m                            _check_type)\n\u001b[1;32m    421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    422\u001b[0m                                                method, path_params,\n\u001b[1;32m    423\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                                _request_timeout,\n\u001b[1;32m    432\u001b[0m                                                _host, _check_type))\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:207\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_response \u001b[39m=\u001b[39m response_data\n\u001b[1;32m    211\u001b[0m return_data \u001b[39m=\u001b[39m response_data\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:200\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    196\u001b[0m     url \u001b[39m=\u001b[39m _host \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    198\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    201\u001b[0m         method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    202\u001b[0m         post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    203\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    204\u001b[0m         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    205\u001b[0m \u001b[39mexcept\u001b[39;00m ApiException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     e\u001b[39m.\u001b[39mbody \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39mbody\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/api_client.py:459\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    452\u001b[0m                                     query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    453\u001b[0m                                     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m                                     _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    457\u001b[0m                                     body\u001b[39m=\u001b[39mbody)\n\u001b[1;32m    458\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPOST\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mPOST(url,\n\u001b[1;32m    460\u001b[0m                                  query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    461\u001b[0m                                  headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    462\u001b[0m                                  post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    463\u001b[0m                                  _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    464\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    465\u001b[0m                                  body\u001b[39m=\u001b[39;49mbody)\n\u001b[1;32m    466\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPUT\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    467\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mPUT(url,\n\u001b[1;32m    468\u001b[0m                                 query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    469\u001b[0m                                 headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    473\u001b[0m                                 body\u001b[39m=\u001b[39mbody)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/rest.py:271\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPOST\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, post_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    270\u001b[0m          body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    272\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    273\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    274\u001b[0m                         post_params\u001b[39m=\u001b[39;49mpost_params,\n\u001b[1;32m    275\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    276\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    277\u001b[0m                         body\u001b[39m=\u001b[39;49mbody)\n",
                        "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.9/site-packages/pinecone/core/client/rest.py:230\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m500\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mstatus \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m599\u001b[39m:\n\u001b[1;32m    228\u001b[0m         \u001b[39mraise\u001b[39;00m ServiceException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mraise\u001b[39;00m ApiException(http_resp\u001b[39m=\u001b[39mr)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
                        "\u001b[0;31mApiException\u001b[0m: (400)\nReason: Bad Request\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=UTF-8', 'date': 'Thu, 11 May 2023 03:54:14 GMT', 'x-envoy-upstream-service-time': '492', 'content-length': '131', 'server': 'envoy'})\nHTTP response body: The index exceeds the project quota of 1 pods by 1 pods. Upgrade your account or change the project settings to increase the quota.\n"
                    ]
                }
            ],
            "source": [
                "# dimensions are for text-embedding-ada-002\n",
                "pinecone.create_index(\"quickstart-index\", dimension=1536, metric=\"euclidean\", pod_type=\"p1\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "667f3cb3-ce18-48d5-b9aa-bfc1a1f0f0f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "pinecone_index = pinecone.Index(\"quickstart-index\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "id": "8ee4473a-094f-4d0a-a825-e1213db07240",
            "metadata": {},
            "source": [
                "#### Load documents, build the PineconeVectorStore and GPTVectorStoreIndex"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "0a2bcc07",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
                "from llama_index.vector_stores import PineconeVectorStore"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "68cbd239-880e-41a3-98d8-dbb3fab55431",
            "metadata": {},
            "outputs": [],
            "source": [
                "# load documents\n",
                "documents = SimpleDirectoryReader('../paul_graham_essay/data').load_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "9ae59590",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index.data_structs.node import Node\n",
                "\n",
                "nodes = [\n",
                "    Node('The Shawshank Redemption', extra_info={\n",
                "        \"author\": \"Stephen King\",\n",
                "        \"theme\": \"Friendship\",\n",
                "    }),\n",
                "    Node('The Godfather', extra_info={\n",
                "        \"director\": \"Francis Ford Coppola\",\n",
                "        \"theme\": \"Mafia\",\n",
                "    }),\n",
                "    Node(\"Inception\", extra_info={\n",
                "        \"director\": \"Christopher Nolan\",\n",
                "    })\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ee6eeecb-d54f-4a71-b5fe-0cda8a5c3e10",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "WARNING:langchain.llms.openai:WARNING! headers is not default parameter.\n",
                        "                    headers was transfered to model_kwargs.\n",
                        "                    Please confirm that headers is what you intended.\n",
                        "WARNING! headers is not default parameter.\n",
                        "                    headers was transfered to model_kwargs.\n",
                        "                    Please confirm that headers is what you intended.\n"
                    ]
                }
            ],
            "source": [
                "from langchain import OpenAI\n",
                "from llama_index.indices.service_context import ServiceContext\n",
                "from llama_index.llm_predictor.base import LLMPredictor\n",
                "\n",
                "\n",
                "vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace='test_05_11')\n",
                "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
                "service_context = ServiceContext.from_defaults(\n",
                "  llm_predictor=LLMPredictor(\n",
                "    llm=OpenAI(\n",
                "      headers={\n",
                "        \"Helicone-Auth\": \"Bearer sk-ss3no7a-o2zeqpi-qlqeipy-it3e4zi\"\n",
                "      }\n",
                "    )\n",
                "  )\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "cad08884",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "> [build_index_from_nodes] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [build_index_from_nodes] Total embedding token usage: 39 tokens\n",
                        "> [build_index_from_nodes] Total embedding token usage: 39 tokens\n"
                    ]
                }
            ],
            "source": [
                "index = GPTVectorStoreIndex(nodes, storage_context=storage_context, service_context=service_context)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "147df357",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
                        "> [retrieve] Total LLM token usage: 0 tokens\n",
                        "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 5 tokens\n",
                        "> [retrieve] Total embedding token usage: 5 tokens\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "[NodeWithScore(node=Node(text='director: Francis Ford Coppola\\ntheme: Mafia\\n\\nThe Godfather', doc_id='e1055b83-d7f5-47bb-b9bb-b8097791deb7', embedding=None, doc_hash='a1b8ddfd0393ce3259e625168434f5e20061c659b95f4859bc060a5292702bca', extra_info={'director': 'Francis Ford Coppola', 'doc_id': 'None', 'document_id': 'None', 'id': 'e1055b83-d7f5-47bb-b9bb-b8097791deb7', 'ref_doc_id': 'None', 'text': 'director: Francis Ford Coppola\\ntheme: Mafia\\n\\nThe Godfather', 'theme': 'Mafia'}, node_info=None, relationships={}), score=0.768340707),\n",
                            " NodeWithScore(node=Node(text='director: Francis Ford Coppola\\ntheme: Mafia\\n\\nThe Godfather', doc_id='c95296bb-743e-430c-aa41-856fbcec9c47', embedding=None, doc_hash='008bc3fb72ea60a2a40842e552028832f973f4d42b23d42bc09b4117d4f65234', extra_info={'director': 'Francis Ford Coppola', 'doc_id': 'None', 'document_id': 'None', 'id': 'c95296bb-743e-430c-aa41-856fbcec9c47', 'ref_doc_id': 'None', 'text': 'director: Francis Ford Coppola\\ntheme: Mafia\\n\\nThe Godfather', 'theme': 'Mafia'}, node_info=None, relationships={}), score=0.768340707)]"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters\n",
                "\n",
                "\n",
                "filters = MetadataFilters(\n",
                "    filters=[\n",
                "        ExactMatchFilter(key='theme', value='Mafia')\n",
                "    ]\n",
                ")\n",
                "\n",
                "retriever = index.as_retriever(filters=filters)\n",
                "retriever.retrieve('What is inception about?')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "1a57e62f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from llama_index.indices.vector_store.auto_retriever.auto_retriever import VectorIndexAutoRetriever\n",
                "from llama_index.indices.vector_store.auto_retriever.schema import MetadataInfo, VectorStoreInfo\n",
                "\n",
                "\n",
                "vector_store_info = VectorStoreInfo(\n",
                "    content_info='movie reviews',\n",
                "    metadata_info=[\n",
                "        MetadataInfo(name='author', type='str', description='Author of the movie'),\n",
                "        MetadataInfo(name='director', type='str', description='Director of the movie'),\n",
                "        MetadataInfo(name='theme', type='str', description='Theme of the movie')\n",
                "    ]\n",
                ")\n",
                "retriever = VectorIndexAutoRetriever(index, vector_store_info=vector_store_info)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "a5c0490d",
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'list' object has no attribute 'filters'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m retriever\u001b[39m.\u001b[39;49mretrieve(\u001b[39m'\u001b[39;49m\u001b[39mSci-fi movie ranking\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/indices/base_retriever.py:21\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     20\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 21\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve(str_or_query_bundle)\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/indices/vector_store/auto_retriever/auto_retriever.py:59\u001b[0m, in \u001b[0;36mVectorIndexAutoRetriever._retrieve\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m     56\u001b[0m query_and_filters \u001b[39m=\u001b[39m cast(QueryAndMetadataFilters, structured_output\u001b[39m.\u001b[39mparsed_output)\n\u001b[1;32m     58\u001b[0m retriever \u001b[39m=\u001b[39m VectorIndexRetriever(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index, filters\u001b[39m=\u001b[39mquery_and_filters\u001b[39m.\u001b[39mfilters)\n\u001b[0;32m---> 59\u001b[0m \u001b[39mreturn\u001b[39;00m retriever\u001b[39m.\u001b[39;49mretrieve(query_and_filters\u001b[39m.\u001b[39;49mquery)\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/indices/base_retriever.py:21\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     20\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 21\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_retrieve(str_or_query_bundle)\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/token_counter/token_counter.py:78\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     77\u001b[0m     \u001b[39mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[0;32m---> 78\u001b[0m         f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m     \u001b[39mreturn\u001b[39;00m f_return_val\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/indices/vector_store/retrievers.py:81\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_context\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_event_end(\n\u001b[1;32m     69\u001b[0m             CBEventType\u001b[39m.\u001b[39mEMBEDDING, payload\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mnum_nodes\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1\u001b[39m}, event_id\u001b[39m=\u001b[39mevent_id\n\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     72\u001b[0m query \u001b[39m=\u001b[39m VectorStoreQuery(\n\u001b[1;32m     73\u001b[0m     query_embedding\u001b[39m=\u001b[39mquery_bundle\u001b[39m.\u001b[39membedding,\n\u001b[1;32m     74\u001b[0m     similarity_top_k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_similarity_top_k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     filters\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filters,\n\u001b[1;32m     80\u001b[0m )\n\u001b[0;32m---> 81\u001b[0m query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vector_store\u001b[39m.\u001b[39;49mquery(query, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs)\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m query_result\u001b[39m.\u001b[39mnodes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[39m# NOTE: vector store does not keep text and returns node indices.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[39m# Need to recover all nodes from docstore\u001b[39;00m\n\u001b[1;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m query_result\u001b[39m.\u001b[39mids \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/vector_stores/pinecone.py:261\u001b[0m, in \u001b[0;36mPineconeVectorStore.query\u001b[0;34m(self, query, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfilter\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m kwargs:\n\u001b[1;32m    258\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot specify filter via both query and kwargs. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mUse kwargs only for pinecone specific items that are \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mnot supported via the generic query interface.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mfilter\u001b[39m \u001b[39m=\u001b[39m _to_pinecone_filter(query\u001b[39m.\u001b[39;49mfilters)\n\u001b[1;32m    262\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[39mfilter\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfilter\u001b[39m\u001b[39m'\u001b[39m, {})\n",
                        "File \u001b[0;32m~/dev/gpt_index/llama_index/vector_stores/pinecone.py:93\u001b[0m, in \u001b[0;36m_to_pinecone_filter\u001b[0;34m(standard_filters)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Convert from standard dataclass to pinecone filter dict.\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m filters \u001b[39m=\u001b[39m {}\n\u001b[0;32m---> 93\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mfilter\u001b[39m \u001b[39min\u001b[39;00m standard_filters\u001b[39m.\u001b[39;49mfilters:\n\u001b[1;32m     94\u001b[0m     filters[\u001b[39mfilter\u001b[39m\u001b[39m.\u001b[39mkey] \u001b[39m=\u001b[39m \u001b[39mfilter\u001b[39m\u001b[39m.\u001b[39mvalue\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m filters\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'filters'"
                    ]
                }
            ],
            "source": [
                "retriever.retrieve('Sci-fi movie ranking')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3a1a9287",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
